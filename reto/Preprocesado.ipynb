{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, Flatten, Dropout, Input, GlobalMaxPooling1D, concatenate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "sacando codigos de folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"C:/Users/Alex/Documents/Cisco Config/Algorithms/Reto/reto/Dataset/version_2\"\n",
        "\n",
        "# Lista de carpetas en el dataset original\n",
        "folder_group = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataFrame \n",
        "Definimos nuestro DataFrame, Path, y empezamos con la lectura de los archivos de Java con UTF-8. El DataFrame contendra los codigos a procesar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=['Nombre1','Code1','Nombre2', 'Code2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = \"C:/Users/Alex/Documents/Cisco Config/Algorithms/Reto/reto/Dataset/version_2\"\n",
        "\n",
        "# Lista de carpetas en el dataset original\n",
        "folder_group = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
        "\n",
        "df = pd.DataFrame(columns=['Nombre1','Code1','Nombre2', 'Code2'])\n",
        "\n",
        "for folder in folder_group:\n",
        "    dataset1 = []\n",
        "    dataset2 = []\n",
        "\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    problem_list = os.listdir(folder_path)\n",
        "\n",
        "    # Eliminar extensión \".java\" del nombre del archivo\n",
        "    problem_list = [os.path.splitext(file)[0] for file in problem_list]\n",
        "\n",
        "    # Leer el primer archivo .java con UTF-8\n",
        "    with open(os.path.join(folder_path, problem_list[0] + '.java'), 'r', encoding='utf-8') as file1:\n",
        "        dataset1.append(file1.read())\n",
        "    d1 = ' '.join(dataset1)\n",
        "\n",
        "    # Leer el segundo archivo .java con UTF-8\n",
        "    with open(os.path.join(folder_path, problem_list[1] + '.java'), 'r', encoding='utf-8') as file2:\n",
        "        dataset2.append(file2.read())\n",
        "    d2 = ' '.join(dataset2)\n",
        "\n",
        "    # Añadir datos al DataFrame\n",
        "    df.loc[len(df.index)] = [problem_list[0], d1, problem_list[1], d2]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Processamiento de Texto\n",
        "Cargamos la informacion de nuestro dataset y verificamos que se cargen correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEL-SwcTQaUX",
        "outputId": "7b7b8e98-ddaf-46ea-ddd6-3f27a8137485"
      },
      "outputs": [],
      "source": [
        "def load_data_from_directory(directory):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    # print(directory)\n",
        "    for label in os.listdir(directory):\n",
        "        # print(label)\n",
        "        # class_dir = os.path.join(directory, label)\n",
        "        class_dir = os.path.join(directory)\n",
        "        # print(class_dir)\n",
        "        if label.endswith(\".txt\"):\n",
        "            file_path = os.path.join(class_dir, label)\n",
        "            # print(file_path)\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                texts.append(file.read())\n",
        "                labels.append(label)\n",
        "                # print(texts)\n",
        "    return texts, labels\n",
        "\n",
        "# Ruta a la carpeta que contiene las subcarpetas 'java', 'python', y 'c'\n",
        "data_directory = 'C:/Users/Alex/Documents/cisco Config/Algorithms/Reto/reto/reto'  # Ajusta esta ruta según sea necesario\n",
        "\n",
        "# Cargar datos desde las carpetas de Java, Python y C\n",
        "java_texts, java_labels = load_data_from_directory(os.path.join(data_directory, 'javaText'))\n",
        "# python_texts, python_labels = load_data_from_directory(os.path.join(data_directory, 'pythonText'))\n",
        "# c_texts, c_labels = load_data_from_directory(os.path.join(data_directory, 'cText'))\n",
        "\n",
        "# Verificar que los datos se han cargado correctamente\n",
        "print(f'Java texts: {len(java_texts)}')\n",
        "# print(f'Python texts: {len(python_texts)}')\n",
        "# print(f'C texts: {len(c_texts)}')\n",
        "\n",
        "# Unir todos los textos y etiquetas\n",
        "texts = java_texts #+ python_texts + c_texts\n",
        "labels = java_labels #+ python_labels + c_labels\n",
        "\n",
        "# Verificar los tamaños de los textos y etiquetas combinados\n",
        "print(f'Total texts: {len(texts)}')\n",
        "print(f'Total labels: {len(labels)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Remover Comentarios\n",
        "Utilizando expresiones regulares, nos deshacemos de commentarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_comments(text):\n",
        "    # Remove all block comments (/* */)\n",
        "    text = re.sub(r'/\\*.*?\\*/', '', text, flags=re.DOTALL)\n",
        "    # Remove all line comments (//)\n",
        "    text = re.sub(r'//.*', '', text)\n",
        "    # Remove all Python line comments (#)\n",
        "    text = re.sub(r'#.*', '', text)\n",
        "    # Remove all Python block comments (''' ''')\n",
        "    text = re.sub(r\"'''(.*?)'''\", '', text, flags=re.DOTALL)\n",
        "    # Remove all Python block comments (\"\"\" \"\"\")\n",
        "    text = re.sub(r'\"\"\"(.*?)\"\"\"', '', text, flags=re.DOTALL)\n",
        "    \n",
        "    # Split the text into lines, clean empty lines\n",
        "    lines = text.split('\\n')\n",
        "    cleaned_lines = [line for line in lines if line.strip() != '']\n",
        "    \n",
        "    cleaned_text = '\\n'.join(cleaned_lines)\n",
        "    return cleaned_text\n",
        "\n",
        "# Ejemplo de uso\n",
        "code = \"\"\"/* Block comment */\n",
        "int x = 0; // Line comment\n",
        "\n",
        "x++; /* Another block\n",
        "comment */\n",
        "\n",
        "System.out.println(x); // Print x\n",
        "\n",
        "# This is a Python comment\n",
        "y = 2 # Another Python comment\n",
        "\n",
        "''' Python block comment\n",
        "spanning multiple lines '''\n",
        "z = 3; // C style line comment\n",
        "\n",
        "\"\"\"\n",
        "cleaned_code = remove_comments(code)\n",
        "print(cleaned_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calculo de Similitudes\n",
        "Realizamos el calculo de similitudes con trancisiones de Markov, inicialmente creando la matriz de transcicion a traves del texto, y realizando la similitud de cosenos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_transition_matrix(text, words):\n",
        "  # Inicializar la matriz de transición\n",
        "  matrix = np.zeros((len(words), len(words)))\n",
        "\n",
        "  # Dividir el texto en palabras\n",
        "  word_list = text.split()\n",
        "\n",
        "  # Calcular las frecuencias de las transiciones entre palabras\n",
        "  for i in range(len(word_list) - 1):\n",
        "      current_word = word_list[i]\n",
        "      next_word = word_list[i + 1]\n",
        "\n",
        "      current_index = words.index(current_word)\n",
        "      next_index = words.index(next_word)\n",
        "\n",
        "      matrix[current_index][next_index] += 1\n",
        "\n",
        "  # Normalizar las filas de la matriz, evitando divisiones por cero\n",
        "  row_sums = matrix.sum(axis=1)\n",
        "  nonzero_rows = np.nonzero(row_sums)\n",
        "  matrix_normalized = np.zeros_like(matrix)\n",
        "  matrix_normalized[nonzero_rows, :] = matrix[nonzero_rows, :] / row_sums[nonzero_rows, np.newaxis]\n",
        "\n",
        "  return matrix_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funcion para obtener archivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_file(file):\n",
        "    return open(file, 'r', encoding='utf-8', errors='ignore').read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Funcion de separacion de palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_words(text1, text2):\n",
        "  splitted_words = list(set(text1.split() + text2.split()))\n",
        "  return splitted_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Claculo de la similitud de coseno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cos_ang(mat1, mat2):\n",
        "  mat2T = np.transpose(mat2)\n",
        "  c = np.dot(mat2T, mat1)\n",
        "  prod_int = np.trace(c)\n",
        "  normA = np.sqrt(np.trace((np.dot(np.transpose(mat1), mat1))))\n",
        "  normB = np.sqrt(np.trace((np.dot(np.transpose(mat2), mat2))))\n",
        "\n",
        "  return prod_int / (normA * normB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_words(text):\n",
        "  file = open(text, \"r\", encoding = 'utf-8', errors ='ignore')\n",
        "  words = file.read()\n",
        "  file.close()\n",
        "\n",
        "  punctuation = [\"_\", \"-\", \".\", \":\", \",\" , \";\", \"(\", \")\", \"?\", \"¿\", \"¡\", \"!\"]\n",
        "  for i in punctuation:\n",
        "      words = words.replace(i, \" \")\n",
        "\n",
        "  words = words.lower()\n",
        "  words = words.replace('\\n', ' ')\n",
        "\n",
        "  return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generar Tabla de Similitudes\n",
        "Generamos nuestra tabla de similitudes/Realiza la evaluacion de la similitud de textos utilizando las funciones anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def similitud(text1, text2):\n",
        "  data1 = remove_comments(text1)\n",
        "  data2 = remove_comments(text2)\n",
        "\n",
        "  split_data = split_words(data1, data2)\n",
        "\n",
        "  mat1 = create_transition_matrix(data1, split_data)\n",
        "  mat2 = create_transition_matrix(data2, split_data)\n",
        "  cos = cos_ang(mat1, mat2)\n",
        "\n",
        "  return cos # Debe retornar un valor %cos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtenemos pruebas aleatoreamente del Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_two_random_texts(texts):\n",
        "\n",
        "  if len(texts) <= 1:\n",
        "    raise ValueError(\"The provided list of texts must contain at least two elements.\")\n",
        "\n",
        "  first_text_index = random.randint(0, len(texts) - 1)\n",
        "  second_text_index = random.randint(0, len(texts) - 1)\n",
        "\n",
        "  # Ensure distinct texts are returned\n",
        "  while first_text_index == second_text_index:\n",
        "    second_text_index = random.randint(0, len(texts) - 1)\n",
        "\n",
        "  return texts[first_text_index],texts[second_text_index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFeEg3t1QLMJ",
        "outputId": "eb2e5caf-286c-4682-8ffb-46ba6eccdf49"
      },
      "outputs": [],
      "source": [
        "similitud(get_two_random_texts(texts)[0], get_two_random_texts(texts)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agregamos una columna de Similitud dependiendo del Resultado, y una identificada como Plagio si la similitud es mayor al 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suVvuYE1h0w5"
      },
      "outputs": [],
      "source": [
        "df['Similitud'] = df.apply(lambda row: similitud(row['Code1'], row['Code2']), axis=1)\n",
        "threshold = 0.8\n",
        "df['Plagio'] = (df['Similitud'] > threshold).astype(int)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos nuestra tabla en CSV para ser leida por nuestros modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizamos la distribución de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualizar la distribución de similitudes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilitud\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribución de Similitudes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Visualizar la distribución de similitudes\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['Similitud'], bins=20, color='blue', edgecolor='black')\n",
        "plt.title('Distribución de Similitudes')\n",
        "plt.xlabel('Similitud')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
